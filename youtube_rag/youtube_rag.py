#!/usr/bin/env python3
"""
YouTube RAG - A lightweight YouTube video Q&A tool / è½»é‡çº§YouTubeè§†é¢‘é—®ç­”å·¥å…·
Supports subtitle extraction and audio transcription to build a searchable knowledge base
æ”¯æŒå­—å¹•æå–å’ŒéŸ³é¢‘è½¬å½•ï¼Œæ„å»ºå¯æœç´¢çš„çŸ¥è¯†åº“

Usage / ä½¿ç”¨æ–¹æ³•:
    python youtube_rag.py "https://www.youtube.com/watch?v=VIDEO_ID"
    
Environment Variables / ç¯å¢ƒå˜é‡:
    OPENAI_API_KEY: OpenAI API key / OpenAI APIå¯†é’¥
"""

import os
import sys
import argparse
import tempfile
import subprocess
from pathlib import Path

from langchain.schema import Document
from openai import OpenAI
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.prompts import ChatPromptTemplate


class YouTubeRAG:
    """YouTube Video RAG Q&A System / YouTubeè§†é¢‘RAGé—®ç­”ç³»ç»Ÿ"""
    
    def __init__(self, chunk_size=1000, chunk_overlap=20):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self._check_openai_key()
        
    def _check_openai_key(self):
        """Check OpenAI API key / æ£€æŸ¥OpenAI APIå¯†é’¥"""
        if not os.getenv("OPENAI_API_KEY"):
            print("âŒ Please set environment variable OPENAI_API_KEY / è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
            sys.exit(1)
    
    def get_video_content(self, url):
        """Get video content, prioritize subtitles, fallback to audio transcription / è·å–è§†é¢‘å†…å®¹ï¼Œä¼˜å…ˆå­—å¹•ï¼Œå¤‡é€‰éŸ³é¢‘è½¬å½•"""
        print(f"ğŸ¥ Processing video / å¤„ç†è§†é¢‘: {url}")
        
        # Try to get subtitles / å°è¯•è·å–å­—å¹•
        content = self._get_subtitles(url)
        if content:
            print("âœ… Using video subtitles / ä½¿ç”¨è§†é¢‘å­—å¹•")
            return Document(page_content=content, metadata={"source": url, "type": "subtitles"})
        
        # Fallback: audio transcription / å¤‡é€‰ï¼šéŸ³é¢‘è½¬å½•
        print("âš ï¸ No subtitles found, starting audio transcription... / æœªæ‰¾åˆ°å­—å¹•ï¼Œå¼€å§‹éŸ³é¢‘è½¬å½•...")
        content = self._transcribe_audio(url)
        print("âœ… Using audio transcription / ä½¿ç”¨éŸ³é¢‘è½¬å½•")
        return Document(page_content=content, metadata={"source": url, "type": "transcription"})
    
    def _get_subtitles(self, url):
        """Get YouTube subtitles / è·å–YouTubeå­—å¹•"""
        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                subtitle_path = Path(tmpdir) / "subtitle.%(ext)s"
                
                cmd = [
                    "python3.12", "-m", "yt_dlp",
                    "--write-subs", "--write-auto-subs",
                    "--sub-langs", "zh,zh-CN,en",
                    "--skip-download",
                    "-o", str(subtitle_path),
                    url
                ]
                
                subprocess.run(cmd, capture_output=True, text=True, check=True)
                
                # Find subtitle files / æŸ¥æ‰¾å­—å¹•æ–‡ä»¶
                for file in Path(tmpdir).glob("*.{vtt,srt}"):
                    return file.read_text(encoding='utf-8')
                    
        except subprocess.CalledProcessError:
            pass
        except Exception as e:
            print(f"Subtitle extraction failed / å­—å¹•è·å–å¤±è´¥: {e}")
        return None
    
    def _transcribe_audio(self, url):
        """Download audio and transcribe / ä¸‹è½½éŸ³é¢‘å¹¶è½¬å½•"""
        with tempfile.TemporaryDirectory() as tmpdir:
            audio_path = Path(tmpdir) / "audio.m4a"
            
            # Download audio / ä¸‹è½½éŸ³é¢‘
            cmd = [
                "python3.12", "-m", "yt_dlp",
                "-f", "bestaudio[ext=m4a]",
                "-o", str(audio_path),
                url
            ]
            subprocess.run(cmd, check=True)
            
            # Whisper transcription / Whisperè½¬å½•
            client = OpenAI()
            with open(audio_path, "rb") as f:
                transcript = client.audio.transcriptions.create(model="whisper-1", file=f)
            
            return transcript.text
    
    def build_knowledge_base(self, documents):
        """Build vector knowledge base / æ„å»ºå‘é‡çŸ¥è¯†åº“"""
        print("ğŸ”§ Building knowledge base... / æ„å»ºçŸ¥è¯†åº“...")
        
        # Text splitting / æ–‡æœ¬åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap
        )
        chunks = text_splitter.split_documents(documents)
        
        # Vectorization and storage / å‘é‡åŒ–å­˜å‚¨
        embeddings = OpenAIEmbeddings()
        vector_store = Chroma.from_documents(chunks, embeddings)
        
        print(f"âœ… Knowledge base built successfully / çŸ¥è¯†åº“æ„å»ºå®Œæˆ, {len(chunks)} chunks total / å…±{len(chunks)}ä¸ªç‰‡æ®µ")
        return vector_store.as_retriever()
    
    def create_qa_chain(self, retriever):
        """Create Q&A chain / åˆ›å»ºé—®ç­”é“¾"""
        system_prompt = """Answer user questions based on the following context.
If you don't know the answer, say "I don't know" and don't make up answers.
Please answer in the same language as the question.

åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
å¦‚æœä¸çŸ¥é“ç­”æ¡ˆï¼Œè¯·è¯´"æˆ‘ä¸çŸ¥é“"ï¼Œä¸è¦ç¼–é€ ç­”æ¡ˆã€‚
è¯·ç”¨ä¸é—®é¢˜ç›¸åŒçš„è¯­è¨€å›ç­”ã€‚

Context / ä¸Šä¸‹æ–‡: {context}"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}")
        ])
        
        llm = ChatOpenAI(temperature=0.1, max_tokens=2048)
        question_answer_chain = create_stuff_documents_chain(llm, prompt)
        
        return create_retrieval_chain(retriever, question_answer_chain)
    
    def interactive_qa(self, rag_chain):
        """Interactive Q&A / äº¤äº’å¼é—®ç­”"""
        print("\nğŸ¤– Q&A system started! Type 'quit' to exit / é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")
        print("-" * 50)
        
        while True:
            try:
                question = input("\nâ“ Ask a question / è¯·æé—®: ").strip()
                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    break
                
                if not question:
                    continue
                
                print("ğŸ¤” Thinking... / æ€è€ƒä¸­...")
                result = rag_chain.invoke({"input": question})
                print(f"\nğŸ’¡ {result['answer']}")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ Error occurred / å‡ºé”™äº†: {e}")
        
        print("\nğŸ‘‹ Goodbye! / å†è§ï¼")


def main():
    parser = argparse.ArgumentParser(description="YouTube Video RAG Q&A Tool / YouTubeè§†é¢‘RAGé—®ç­”å·¥å…·")
    parser.add_argument("url", help="YouTube video URL / YouTubeè§†é¢‘URL")
    parser.add_argument("--chunk-size", type=int, default=1000, help="Text chunk size / æ–‡æœ¬å—å¤§å°")
    parser.add_argument("--chunk-overlap", type=int, default=20, help="Text chunk overlap / æ–‡æœ¬å—é‡å ")
    
    args = parser.parse_args()
    
    # Create RAG system / åˆ›å»ºRAGç³»ç»Ÿ
    rag = YouTubeRAG(chunk_size=args.chunk_size, chunk_overlap=args.chunk_overlap)
    
    try:
        # Get video content / è·å–è§†é¢‘å†…å®¹
        document = rag.get_video_content(args.url)
        
        # Build knowledge base / æ„å»ºçŸ¥è¯†åº“
        retriever = rag.build_knowledge_base([document])
        
        # Create Q&A chain / åˆ›å»ºé—®ç­”é“¾
        qa_chain = rag.create_qa_chain(retriever)
        
        # Start interactive Q&A / å¯åŠ¨äº¤äº’å¼é—®ç­”
        rag.interactive_qa(qa_chain)
        
    except Exception as e:
        print(f"âŒ Execution failed / è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()